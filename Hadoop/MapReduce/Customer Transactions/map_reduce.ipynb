{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving variables to access the file locations\n",
    "articles='articles.csv'\n",
    "customers='customers.csv'\n",
    "transactions='transactions.csv'\n",
    "transactions_small ='transactions_small.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For each garment group, show the most frequent product, the second most frequent section and the most frequent department it appears inside the article.csv file; make sure output has the following schema:\n",
    "\n",
    "            garment_group_name, prod_name, section_name,  department_name\n",
    "\n",
    "The product names are stored in \"prod_name\", the deparment name in \"department_name\", the garment group in \"garment_group_name\" and the section in \"section_name\". In case that there are multiple departments, garment groups or sections with the same number of occurences, you may resolve these conflicts randomly, i.e. pick one of them arbitrarily. In case there is only one section, or all sections appear with the same frequency, just pick the most frequent one, and resolve conflicts randomly. \n",
    "\n",
    "Make sure that your program correctly deals with the header, and possible sparse values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mymrjob1.py\n"
     ]
    }
   ],
   "source": [
    "%%file mymrjob1.py\n",
    "# This will create a local file to run your MapReduce program  \n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from mrjob.util import log_to_stream, log_to_null\n",
    "from mr3px.csvprotocol import CsvProtocol\n",
    "import csv \n",
    "import logging\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "class MyMRJob1(MRJob):\n",
    "    \n",
    "    OUTPUT_PROTOCOL = CsvProtocol\n",
    "    \n",
    "    def set_up_logging(cls, quiet=False, verbose=False, stream=None):  \n",
    "        log_to_stream(name='mrjob', debug=verbose, stream=stream)\n",
    "        log_to_stream(name='__main__', debug=verbose, stream=stream)\n",
    "        \n",
    "    def mapper(self, _, line):\n",
    "        result = next(csv.reader([line]))\n",
    "        \n",
    "        garment_group_name = result[23]\n",
    "        prod_name = result[2]\n",
    "        section_name = result[21]\n",
    "        department_name = result[15]\n",
    "        \n",
    "        if result[0] != 'article_id':\n",
    "            yield (garment_group_name, 'prod_name', prod_name), 1\n",
    "            yield (garment_group_name, 'section_name', section_name), 1\n",
    "            yield (garment_group_name, 'department_name', department_name), 1\n",
    "        \n",
    "    def combiner(self, key, valuelist):\n",
    "        yield key, sum(valuelist)\n",
    "        \n",
    "    def reducer(self, key, valuelist):\n",
    "        yield key[:-1], (key[-1], sum(valuelist))\n",
    "        \n",
    "    def reducer2(self, key, valuelist):\n",
    "        frequency = max(valuelist, key=lambda x: x[1])\n",
    "        yield key[0], (key[1], frequency[0])\n",
    "        \n",
    "    def reducer3(self,key,valuelist):\n",
    "        prod_name, section_name, department_name = [*dict(valuelist).values()]\n",
    "        yield None, (key, prod_name, section_name, department_name)\n",
    "\n",
    "    def steps(self):\n",
    "        first_step = MRStep(\n",
    "            mapper=self.mapper, \n",
    "            combiner=self.combiner, \n",
    "            reducer=self.reducer\n",
    "        )\n",
    "        \n",
    "        second_step = MRStep(\n",
    "            reducer=self.reducer2\n",
    "        )\n",
    "        \n",
    "        third_step = MRStep(\n",
    "            reducer=self.reducer3\n",
    "        )\n",
    "        \n",
    "        return [ first_step, second_step, third_step ]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MyMRJob1.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3.6 mymrjob1.py  $articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a local MRjob "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a Hadoop job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "! HADOOP_HOME=/opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/  python3.6 mymrjob1.py -r hadoop hdfs://$articles > output.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "For all customers older than 30 years, show the number of transactions items they were involved in with articles from department with name 'Jersey Basic' or 'Shirt'. \n",
    "\n",
    "\n",
    "Make sure to have the following format in your final output:\n",
    "\n",
    "            customer_id,count_transactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mymrjob2.py\n"
     ]
    }
   ],
   "source": [
    "%%file mymrjob2.py\n",
    "# This will create a local file to run your MapReduce program  \n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from mrjob.util import log_to_stream, log_to_null\n",
    "from mr3px.csvprotocol import CsvProtocol\n",
    "import csv \n",
    "import logging\n",
    "  \n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "class MyMRJob2(MRJob):\n",
    "    \n",
    "    OUTPUT_PROTOCOL = CsvProtocol  # write output as CSV\n",
    "    \n",
    "    def set_up_logging(cls, quiet=False, verbose=False, stream=None):  \n",
    "        log_to_stream(name='mrjob', debug=verbose, stream=stream)\n",
    "        log_to_stream(name='__main__', debug=verbose, stream=stream)\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        result = next(csv.reader([line]))\n",
    "        \n",
    "        input_size = len(result)\n",
    "        \n",
    "        try:\n",
    "            if input_size == 25: \n",
    "                if 'Jersey Basic' in result[15] or 'Shirt' in result[15]:\n",
    "                    article_id  = result[0]\n",
    "                    yield ('article', article_id), 1\n",
    "\n",
    "            elif input_size == 7 and int(result[5]) > 30:\n",
    "                customer_id = result[0]\n",
    "                yield ('customer', customer_id), 1\n",
    "\n",
    "            elif input_size == 5: \n",
    "                customer_id = result[1]\n",
    "                article_id  = result[2]\n",
    "                yield (customer_id, article_id), 1\n",
    "                \n",
    "        except ValueError:\n",
    "            return 0\n",
    "   \n",
    "    def combiner(self, key, valuelist):\n",
    "        if key[0] != \"customer\" and key[0] != \"article\":\n",
    "            yield ('customer', key[0]), 1\n",
    "            \n",
    "        else:\n",
    "            yield key, 1\n",
    "            \n",
    "    def reducer(self, key, valuelist):\n",
    "        if key[0] == \"customer\":\n",
    "            yield None, (key[1], sum(valuelist))\n",
    "            \n",
    "    def steps(self):\n",
    "        first_step = MRStep(\n",
    "            mapper=self.mapper,\n",
    "            combiner=self.combiner, \n",
    "            reducer=self.reducer\n",
    "        )\n",
    "        \n",
    "        return [ first_step ]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MyMRJob2.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3.6 mymrjob2.py  $articles $transactions_small $customers > output2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! HADOOP_HOME=/opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/  python3.6  mymrjob2.py -r hadoop hdfs://$articles hdfs://$transactions hdfs://$customers > output2.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
